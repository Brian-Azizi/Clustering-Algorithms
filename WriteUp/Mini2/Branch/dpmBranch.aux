\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\newlabel{sect:Intro}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Conjugate Bayesian Analysis of Categorical Variables}{1}}
\newlabel{sect:parametric}{{2}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Discrete Random Variables and the Categorical Distribution}{1}}
\newlabel{eqn:catpmf}{{1}{1}}
\newlabel{eqn:kronecker}{{2}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The probability density function of a discrete random variable that can occupy 3 possible states, $f(x) = \Cat  (x\tmspace  +\thinmuskip {.1667em}|\tmspace  +\thinmuskip {.1667em}\pi _1,\pi _2,\pi _3)$.}}{2}}
\newlabel{fig:pmf}{{1}{2}}
\newlabel{eqn:catpdf}{{3}{2}}
\newlabel{eqn:simplex}{{4}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The 3-dimensional probability simplex $\Delta _3$.}}{2}}
\newlabel{fig:simplex}{{2}{2}}
\newlabel{eqn:catlik}{{5}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Maximum Likelihood Inference of Categorical Variables}{2}}
\newlabel{eqn:catlagrange}{{6}{2}}
\citation{ywt07}
\newlabel{dldlambda}{{7}{3}}
\newlabel{dldpi}{{9}{3}}
\newlabel{eqn:catML}{{10}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Bayesian Inference and Conjugacy}{3}}
\newlabel{sect:conjugacy}{{2.3}{3}}
\newlabel{eqn:bayes}{{11}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}The Dirichlet Distribution}{3}}
\newlabel{sect:dirdistro}{{2.4}{3}}
\newlabel{eqn:dirpdf}{{13}{3}}
\newlabel{eqn:dirmean1}{{14}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Examples of Dirichlet distributions on $\Delta _3$. (Figure from \cite  {ywt07})}}{4}}
\newlabel{fig:dir}{{3}{4}}
\newlabel{eqn:dirmean}{{15}{4}}
\newlabel{eqn:dirvar}{{16}{4}}
\newlabel{eqn:dirpost}{{17}{4}}
\citation{Bishop,Murphy}
\newlabel{eqn:dirpriorpredictive}{{19}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Definition of the Dirichlet Process}{5}}
\newlabel{sect:dp}{{3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}From the Dirichlet Distribution to the Dirichlet Process}{5}}
\newlabel{eqn:diracmeasure}{{21}{5}}
\newlabel{eqn:discretemeasure}{{22}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}A mathematical definition of the Dirichlet process}{5}}
\citation{ferguson1973}
\citation{Teh2010a}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A finite partition of $\Omega $.}}{6}}
\newlabel{fig:partition}{{4}{6}}
\newlabel{eqn:dpdef}{{23}{6}}
\newlabel{eqn:meandp}{{24}{6}}
\newlabel{eqn:vardp}{{25}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Representations of the Dirichlet Process}{6}}
\newlabel{sect:representations}{{4}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Conjugacy and the Blackwell-MacQueen Urn Scheme}{6}}
\newlabel{eqn:dppriorpredictive}{{26}{6}}
\newlabel{eqn:dppost1}{{27}{6}}
\newlabel{eqn:dppost2}{{28}{6}}
\citation{blackwell1973}
\citation{blackwell1973}
\citation{ewens1990}
\citation{sethuraman94}
\newlabel{eqn:dppostpred}{{30}{7}}
\newlabel{eqn:dpprobsame}{{31}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}The Stick-breaking construction}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Stick-breaking construction of $\boldsymbol  \pi $.}}{8}}
\newlabel{fig:stick}{{5}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Clustering property of the Dirichlet process and the Chinese Restaurant Process}{8}}
\newlabel{sect:crp}{{4.3}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The Chinese restaurant process. 5 customers are currently seated across 2 tables ($K=2$). The 6th customer is waiting to be seated. The quantities on the arrows are the probabilities with which customer 6 will be seated at the corresponding table. Currently, the induced partition over the integers $\{1,2,3,4,5\}$ is $\{\{1,3,4\},\{2,5\}\}$.}}{8}}
\newlabel{fig:crp}{{6}{8}}
\newlabel{eqn:crp}{{36}{8}}
\citation{neal2000}
\@writefile{toc}{\contentsline {section}{\numberline {5}The Dirichlet Process Mixture}{9}}
\newlabel{sect:DPM}{{5}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Density Estimation and Clustering using Dirichlet Processes}{9}}
\newlabel{eqn:dpm}{{39}{9}}
\newlabel{eqn:dpmmixture}{{41}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Inference in Dirichlet Process mixtures}{9}}
\citation{ishwaran2001}
\citation{jain2004}
\citation{fearnhead2004}
\citation{minka2003}
\citation{blei2006}
\citation{escobar1994}
\citation{escobar1995}
\citation{neal2000}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Gibbs Sampling}{10}}
\newlabel{eqn:Gibbs}{{42}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}A na{\"i}ve Gibbs sampler for Dirichlet Process Mixtures}{10}}
\newlabel{eqn:dpmpostpred}{{43}{10}}
\newlabel{eqn:dpmgibbs1}{{44}{10}}
\@writefile{lop}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Na{\"i}ve Gibbs sampler for DP mixtures}}{11}}
\newlabel{alg:naive}{{1}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}The standard Gibbs Sampler for Dirichlet Process Mixtures}{11}}
\newlabel{eqn:phi_k}{{46}{11}}
\newlabel{eqn:phi_K+1}{{48}{11}}
\newlabel{eqn:samplez}{{49}{11}}
\newlabel{eqn:newcluster}{{50}{11}}
\citation{maceachern1994}
\citation{neal2000}
\citation{neal2000,orbanz2014}
\@writefile{lop}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Gibbs sampling inference for DP mixtures}}{12}}
\newlabel{alg:gibbs2}{{2}{12}}
\newlabel{eqn:sampletheta}{{51}{12}}
\newlabel{eqn:dompostpred}{{52}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Implementation of the Normal-Inverse-Wishart Dirichlet Process Mixture model}{12}}
\newlabel{sect:implementation}{{6}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Conjugate Bayesian analysis of the multivariate Gaussian}{12}}
\citation{murphy2007}
\citation{armadillo}
\newlabel{eqn:NIWpost}{{59}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Implementation details}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Sampling from the Categorical distribution}{13}}
\citation{smith1972}
\@writefile{lop}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Smith \& Hocking procedure \cite  {smith1972} for generating $\mathcal  {IW}(\boldsymbol  S,\nu )$ distributed random matrices}}{14}}
\newlabel{alg:IW}{{3}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Sampling from the Normal-inverse-Wishart distribution}{14}}
\citation{box1958}
\citation{marsaglia2000}
\citation{Murphy}
\citation{pitman1997,teh2006a}
\@writefile{lop}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Procedure for sampling $\boldsymbol  x \sim \mathcal  {N}(\boldsymbol  m,\boldsymbol  S)$}}{15}}
\newlabel{alg:gauss}{{4}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Demonstration}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Extensions and Further Work}{15}}
\newlabel{sect:conclusion}{{7}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Clustering of $N$ data points using the Dirichlet process mixture. (a) $N=1000$ (b) $N=3000$ (c) $N=6000$ (d) $N=10000$. Each data set contains the previous one as a subset.}}{16}}
\newlabel{fig:size}{{7}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Posterior distribution of the number of clusters $K$ for the data sets in figure 7\hbox {}. The Gibbs sampler was run for 1200 iterations and we discarded the first 200 as burn-in.}}{16}}
\newlabel{fig:hist}{{8}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Clustering of the data set in figure 7\hbox {} (d) using the Dirichlet process mixture model. The inital number of clusters is set to $K=100$ and we show the output of the algorithm after $j$ iterations. (a) $j=10$ (b) $j=100$ (c) $j=300$. Panel (d) plots $K$ against the number of iterations.}}{17}}
\newlabel{fig:iter}{{9}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Example an application of the Diirichlet process mixture to image segmentation. The original image is on the left and the segmented image is on the right. The mode of the posterior distribution for the number of clusters $K$ is $K=19$.}}{17}}
\newlabel{fig:pics}{{10}{17}}
\citation{maceachern1999}
\citation{teh2006b}
\bibstyle{elsarticle-num}
\bibdata{references.bib}
\bibcite{ywt07}{{1}{}{{}}{{}}}
\bibcite{Bishop}{{2}{}{{}}{{}}}
\bibcite{Murphy}{{3}{}{{}}{{}}}
\bibcite{ferguson1973}{{4}{}{{}}{{}}}
\bibcite{Teh2010a}{{5}{}{{}}{{}}}
\bibcite{blackwell1973}{{6}{}{{}}{{}}}
\bibcite{ewens1990}{{7}{}{{}}{{}}}
\bibcite{sethuraman94}{{8}{}{{}}{{}}}
\bibcite{neal2000}{{9}{}{{}}{{}}}
\bibcite{ishwaran2001}{{10}{}{{}}{{}}}
\bibcite{jain2004}{{11}{}{{}}{{}}}
\bibcite{fearnhead2004}{{12}{}{{}}{{}}}
\bibcite{minka2003}{{13}{}{{}}{{}}}
\bibcite{blei2006}{{14}{}{{}}{{}}}
\bibcite{escobar1994}{{15}{}{{}}{{}}}
\bibcite{escobar1995}{{16}{}{{}}{{}}}
\bibcite{maceachern1994}{{17}{}{{}}{{}}}
\bibcite{orbanz2014}{{18}{}{{}}{{}}}
\bibcite{murphy2007}{{19}{}{{}}{{}}}
\bibcite{armadillo}{{20}{}{{}}{{}}}
\bibcite{smith1972}{{21}{}{{}}{{}}}
\bibcite{box1958}{{22}{}{{}}{{}}}
\bibcite{marsaglia2000}{{23}{}{{}}{{}}}
\bibcite{pitman1997}{{24}{}{{}}{{}}}
\bibcite{teh2006a}{{25}{}{{}}{{}}}
\bibcite{maceachern1999}{{26}{}{{}}{{}}}
\bibcite{teh2006b}{{27}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
